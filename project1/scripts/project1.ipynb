{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import implementations\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#apply method\n",
    "def get_w_loss(y,x,method,initial_w=0,max_iters=10,gamma=0.00000005,threshold=1e-08,logs=False,batch_size=1,lambda_=0.005, store=False):\n",
    "    \"\"\"applies the algorithm described by <method>. by default as the awaited behaviour for the project, but offers some possible enhancements (batch_size,threshold, logs, store)\n",
    "    Args:\n",
    "        y (numpy.ndarray): An array with shape (n,1)\n",
    "        tx (numpy.ndarray): An array with shape (n,m)\n",
    "        method (int): 1 -> least_squares_GD\n",
    "                      2 -> stochastic_gradient_descent\n",
    "                      3 -> least_squares\n",
    "                      4 -> ridge_regression\n",
    "                      5 -> logistic_regression_gradient_descent\n",
    "        initial_w (Union[float, numpy.ndarray], optional): if a int is set w will start with an array. Defaults to 0.\n",
    "        max_iters (int, optional): number of iterations (only for descent algorithms). Defaults to 10.\n",
    "        gamma (float, optional): descent scale factor (only for descent algorithms). Defaults to 0.00000005.\n",
    "        threshold (float, optional): threshold to prevent divergence in case of linear separability (I assume). Defaults to 1e-08.\n",
    "        log (bool, optional): if True step by step logs are displayed (only for descent algorithms). Defaults to False.\n",
    "        batch_size (int, optional): size of the sample on which to compute the partial gradient for stochastic gradient descent algorithm. Defaults to 1.\n",
    "        lambda_ (float, optional): regularization factor with good values allows to limit overfitting and underfitting (only for ridge_regression and reg_logistic_regression). Defaults to 0.005.\n",
    "        store (bool, optional): [description]. Defaults to False.\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    :raises ValueError: if method is not <6\n",
    "    \"\"\"\n",
    "    initial_=np.array([initial_w]*len(x[0]))\n",
    "    if(method==1):\n",
    "        return implementations.least_squares_GD(y,x, initial_, max_iters, gamma, logs)\n",
    "    elif(method==2): \n",
    "        return implementations.stochastic_gradient_descent(y,x, initial_, max_iters, gamma, batch_size, logs)\n",
    "    elif(method==3):\n",
    "        return implementations.least_squares(y,x)\n",
    "    elif(method==4):\n",
    "        return implementations.ridge_regression(y,x, lambda_=lambda_)\n",
    "    elif(method==5):\n",
    "        return implementations.logistic_regression_gradient_descent(y,x,initial_w,max_iters,gamma,threshold,logs,store)\n",
    "    elif(method==6):\n",
    "        #TODO: \n",
    "        return implementations.reg_logistic_regression()\n",
    "    else:\n",
    "        return ValueError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module &#39;implementations&#39; has no attribute &#39;logistic_regression_gradient_descent&#39;",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-31-5d8efee856e1&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#print(np.where(mls==min(mls)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#print(mls)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---&gt; 10\u001b[0;31m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_w_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m&lt;ipython-input-23-2a286f660c08&gt;\u001b[0m in \u001b[0;36mget_w_loss\u001b[0;34m(y, x, method, initial_w, max_iters, gamma, threshold, logs, batch_size, lambda_, store)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimplementations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mridge_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---&gt; 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimplementations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic_regression_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#TODO:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module &#39;implementations&#39; has no attribute &#39;logistic_regression_gradient_descent&#39;"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = '../data/submission.csv'\n",
    "mls=[]\n",
    "weightss=[]\n",
    "#for i in range(-10,10,1):\n",
    "#    ml,weights=get_w(y,tX,2,i,max_iters=1000,log=False)\n",
    "#    mls.append(ml)\n",
    "#    weightss.append(weights)\n",
    "#print(np.where(mls==min(mls)))\n",
    "#print(mls)\n",
    "weights=get_w_loss(y,tX,5)\n",
    "print(weights)\n",
    "\n",
    "#weights=weightss[np.where(mls==min(mls))[0][0]]\n",
    "\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}